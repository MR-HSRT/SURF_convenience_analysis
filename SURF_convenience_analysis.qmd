---
title: "Deskriptive Auswertung SURF Convenience Umfragedaten"
format:
  html:
    toc: true
    number-sections: true
    theme: cosmo
execute:
  echo: false
  warning: false
  message: false
  cache: false
---

```{r}
#| label: setup
#| include: false

# ----------------------------
# 1) Pakete installieren, prüfen und laden
# ----------------------------

# Stabiler CRAN-Mirror (wichtig, falls RStudio alte Repos nutzt)
options(repos = c(CRAN = "https://cloud.r-project.org"))

required_pkgs <- c(
  "here","readr","dplyr","tidyr","stringr","janitor","labelled",
  "psych","gtsummary","flextable","ggplot2","scales","broom","knitr",
  "readxl"
)

# Fehlende Pakete ermitteln
missing_pkgs <- required_pkgs[!vapply(required_pkgs, requireNamespace, logical(1), quietly = TRUE)]

# Fehlende Pakete installieren (ohne Stop; mit klarer Meldung)
if (length(missing_pkgs) > 0) {
  message("Installiere fehlende Pakete: ", paste(missing_pkgs, collapse = ", "))
  tryCatch(
    {
      install.packages(missing_pkgs, dependencies = TRUE)
    },
    error = function(e) {
      message("Paketinstallation fehlgeschlagen: ", conditionMessage(e))
      message("Hinweis: Bitte R/RStudio neu starten und erneut ausführen. ",
              "Falls weiterhin Probleme: R als Admin starten oder Schreibrechte für die Library prüfen.")
    }
  )
}

# Pakete laden (leise; ohne Fehlermeldungsflut)
loaded <- vapply(required_pkgs, function(pkg) {
  suppressWarnings(suppressPackageStartupMessages(require(pkg, character.only = TRUE)))
}, logical(1))

# Wenn etwas trotz Install-Versuch nicht ladbar ist: nur eine kompakte Warnung
if (any(!loaded)) {
  warning("Folgende Pakete konnten nicht geladen werden: ",
          paste(required_pkgs[!loaded], collapse = ", "),
          call. = FALSE)
}

# ----------------------------
# 2) Ordnerstruktur erstellen
# ----------------------------
dir.create(here::here("data", "raw"),        recursive = TRUE, showWarnings = FALSE)
dir.create(here::here("data", "processed"),  recursive = TRUE, showWarnings = FALSE)
dir.create(here::here("outputs", "plots"),   recursive = TRUE, showWarnings = FALSE)
dir.create(here::here("outputs", "tables"),  recursive = TRUE, showWarnings = FALSE)

# ----------------------------
# 3) Reproduzierbarkeit
# ----------------------------
set.seed(1234)

PLOTS_DIR  <- here::here("outputs", "plots")
TABLES_DIR <- here::here("outputs", "tables")

# ----------------------------
# 4) .gitignore sicherstellen
# ----------------------------
gitignore_path <- here::here(".gitignore")

gitignore_content <- c(
  "# --- R / RStudio ---",
  ".Rproj.user/",
  ".Rhistory",
  ".RData",
  ".Ruserdata",
  "",
  "# --- Data files ---",
  "*.csv",
  "*.xlsx",
  "*.json",
  "",
  "# --- Quarto ---",
  "*_cache/",
  "*_files/",
  "",
  "# --- Private data (NEVER commit) ---",
  "data/raw/",
  "data/processed/",
  "",
  "# --- Local secrets ---",
  ".env"
)

if (!file.exists(gitignore_path)) {
  writeLines(gitignore_content, gitignore_path)
} else {
  existing_raw  <- readLines(gitignore_path, warn = FALSE)
  existing_trim <- trimws(existing_raw)

  to_add <- gitignore_content[!gitignore_content %in% existing_trim]

  if (length(to_add) > 0) {
    writeLines(c(existing_raw, to_add), gitignore_path)
  }
}

```

```{r}
#| label: import-data
#| include: false

# Pfad zur neuen LimeSurvey-Exceldatei
xlsx_path <- here::here("data", "raw", "results-survey739381.xlsx")

# Einlesen (Excel)
daten <- readxl::read_xlsx(xlsx_path)

# Spaltennamen bereinigen (snake_case)
daten <- janitor::clean_names(daten)

```

# Datenreport: SURF Convenience Survey

Vom XXX bis zum 28.02.2026 wird das SURF Convenience-Survey von den SURF Projektpartnern digital über unterschiedliche Kanäle gestreut.
Zu diesem Zweck wurde die Online-Umfrage über interne und externe Newsletter, Social Media Plattformen, und Online-Foren gestreut.
Ziel dieser ersten Umfrage ist es, eine erste Erhebung der Akzeptanz von und Präferenzen für die digitale SURF-Plattform zu erheben,
und einen umfangreichen Test der Umfrage durchzuführen. Die so erhobenen Ergebnisse fliessen in die Weiterentwicklung der Umfrage und andere Projektbestandteile,
sowie in die praktische Entwicklungsarbeit der Umfrage ein.

## Aufbau und Inhalte der Umfrage

XXXX

## Datenqualität

Aufgrund des convenience-Charakters (hier Fußnote einfügen, die "convenience-Charakter" erklärt) der Umfrage muss ein besonderes Augenmerk auf die Qualität der erhobenen Daten gelegt werden. In diesem Abschnitt werden daher folgende Merkmale der Antwortsqualität geprüft, tabelliert, und visualisiert.

```{r}
#| label: qc-definition-table

qc_definitions <- tibble::tibble(
  Check = c("Speeding", "Straightlining"),
  Indikator = c("Interviewdauer", "Standardabweichung innerhalb von Skalenbatterien"),
  Kriterium = c(
    "Interviewdauer < 1/3 der Median-Dauer",
    "SD über alle Skalenitems = 0"
  ),
  Interpretation = c(
    "Sehr schnelle Bearbeitung deutet auf Satisficing / oberflächliche Bearbeitung hin.",
    "Konstante Antworten über alle Items deuten auf inhaltsloses Durchklicken hin."
  )
)

qc_definitions |> 
  flextable::flextable() |> 
  flextable::autofit()

```

In einem zweiten Schritt werden üblicherweise Fälle entfernt, die Auffälligkeiten im Hinblick auf diese Datenqualitätsmerkmale aufweisen. Da die erhobene Daten jedoch keine derartigen Fälle aufweisen, können sie vollständig in die folgenden Analysen einbezogen werden.

### Speeding

Speeding bezeichnet sehr schnelle Umfragebearbeitung und deutet auf Satisficing, bzw. oberflächliche Bearbeitung der Umfrage, oder sogar "Durchklicken" ohne inhaltliche Auseinandersetzung hin und wird im Rahmen dieser Befragung formal definiert als Interviewdauer < 1/3 der Median-Dauer (Median-Dauer = XXX Min., XXX Sek.). Im Folgenden wird die Anzahl der so als 'Speeder' definierbaren Fälle aufgeführt und visualisiert. Zuvor wird die Bearbeitungsdauer des Online-Surveys visualisiert.

```{r}
#| label: create-surf-check

surf_check <- daten

```

```{r}
#| label: qc-time-histogram-all

surf_check <- surf_check |>
  dplyr::mutate(interview_min = as.numeric(interviewtime) / 60)

q_all <- quantile(surf_check$interview_min,
                  probs = c(.05, .25, .50, .75, .95),
                  na.rm = TRUE)

median_min     <- q_all[3]
cutoff_speeder <- median_min / 3

p_all <- ggplot2::ggplot(surf_check, ggplot2::aes(x = interview_min)) +
  ggplot2::geom_histogram(bins = 35) +
  ggplot2::geom_vline(xintercept = as.numeric(q_all), linetype = "dotted") +
  ggplot2::geom_vline(xintercept = median_min, linetype = "dashed") +
  ggplot2::geom_vline(xintercept = cutoff_speeder, linetype = "dashed") +
  ggplot2::labs(
    title = "Verteilung der Bearbeitungszeit – alle Interviews",
    x = "Bearbeitungszeit (Minuten)",
    y = "Anzahl Befragte"
  ) +
  ggplot2::annotate(
    "text",
    x = Inf, y = Inf,
    hjust = 1.05, vjust = 1.1, size = 3.2,
    label = paste0(
      "Median: ", round(median_min, 2), " min\n",
      "Cutoff: ", round(cutoff_speeder, 2), " min\n",
      "Q05: ", round(q_all[1], 2), " | Q25: ", round(q_all[2], 2), "\n",
      "Q50: ", round(q_all[3], 2), " | Q75: ", round(q_all[4], 2), "\n",
      "Q95: ", round(q_all[5], 2)
    )
  ) +
  ggplot2::theme_minimal(base_size = 12)

ggplot2::ggsave(
  filename = file.path(PLOTS_DIR, "qc_bearbeitungszeit_alle_faelle.png"),
  plot = p_all,
  width = 8, height = 5, dpi = 300
)

p_all

```
**Eingezeichnet:** Quantile Q05, Q25, Q50, Q75 und Q95 (punktierte Linien), Median der Bearbeitungszeit (gestrichelte Linie) sowie das Speeder-Kriterium als gestrichelte Linie bei einem Drittel des Medians.

Diese Analyse verdeutlicht, dass eine Reihe von Fällen eine besonders hohe Bearbeitungsdauer aufweisen. Diese rühren vermutlich von Unterbrechnungen während der Bearbeitung des Surveys her. Da diese Fälle sich mit einme Maximum von `r round(max(surf_check$interview_min, na.rm = TRUE), 2)` jedoch im Rahmen annehmbarer Werte bewegen, werden Sie weiterhin in die Analyse eingeschlossen. Gleichzeitig wird eine Reihen von Fällen identifiziert, die eine besonders niedriger Bearbeitungsdauer aufweisen, und potenziell als 'Speeder' gelten können. Der eingezeichnete Cutoff von `r round(median(surf_check$interview_min, na.rm = TRUE) / 3, 1)`, was einem Drittel des Medians von `r round(median(surf_check$interview_min, na.rm = TRUE))` entspricht, verdeutlicht jedoch, dass keine Fälle im Sample unter diese Grenze fallen. Die Daten sind damit, gemäß der hier genutzten Definition, nicht von Speeding betroffen.

### Straightlining

Straightlining wurde als konstantes Antwortmuster über Itembatterien hinweg definiert. Für jede von vier zentralen Skalenbatterien wurde pro Fall die Standardabweichung der Antworten berechnet. Ein Fall wurde als Straightliner klassifiziert, wenn mindestens 60 % der Items einer Batterie beantwortet wurden und die Standardabweichung innerhalb dieser Batterie gleich Null war. Zusätzlich wurde ein Gesamtindikator gebildet, der Straightlining in mindestens einer Batterie abbildet.


```{r}
#| label: qc-straightlining

scale_vars <- names(surf_check)[
stringr::str_detect(names(surf_check), "^(flex_|config_|info_content_|info_form_)")
]

min_answered <- max(5, ceiling(length(scale_vars) * 0.6))

surf_check <- surf_check |>
dplyr::rowwise() |>
dplyr::mutate(
n_answered_scales = sum(!is.na(dplyr::c_across(dplyr::all_of(scale_vars)))),
straightline_sd   = sd(dplyr::c_across(dplyr::all_of(scale_vars)), na.rm = TRUE),
flag_straightline = (n_answered_scales >= min_answered) & (straightline_sd == 0)
) |>
dplyr::ungroup()


```

```{r}

#| label: qc-straightlining-table

sl_tab <- surf_check |>
dplyr::mutate(Straightlining = ifelse(flag_straightline, "Straightliner", "Keine Straightliner")) |>
dplyr::count(Straightlining) |>
dplyr::mutate(Anteil = round(n / sum(n) * 100, 1))

flextable::flextable(sl_tab) |>
flextable::set_header_labels(
Straightlining = "Kategorie",
n = "Anzahl",
Anteil = "Anteil (%)"
) |>
flextable::autofit()


```
Auf Basis dieses Qualitätsstandards können ebenfalls keine problematischen Fälle in den erhobenen Daten identifiziert werden.

Weder auf Basis der Bearbeitungsdauer (Speeding) noch hinsichtlich konstanter Antwortmuster (Straightlining) können somit systematisch problematische Fälle identifiziert werden. Die Verteilungen der Bearbeitungszeiten sowie die batterie-spezifischen Straightlining-Indikatoren zeigten keine auffälligen Muster, sodass alle Fälle in die weitere Analyse einbezogen wurden.

# Deskriptive Analyse: SURF Convenience Survey

```{r}
#| label: clean-variables

# Alle Variablen, die NUR technische Metadaten sind
drop_patterns <- c(
  "^id$",
  "^submitdate$",
  "^lastpage$",
  "^startlanguage$",
  "^seed$",
  "^rand_freq$",
  "^video_info$",
  "^immersion$",
  "^control_info$",
  "^cheap_talk_script$",
  "^restrictions_year$",
  "^redirect_info_end$",
  "^survey_feedback$",
  "^interviewtime$",
  "^group_time",
  "_time$"
)

drop_vars <- names(daten)[
  stringr::str_detect(names(daten), paste(drop_patterns, collapse = "|"))
]

# Datensatz bereinigen
daten_clean <- daten |> 
  dplyr::select(-dplyr::all_of(drop_vars))

# Übersicht
cat("Entfernte Variablen:\n")
cat(paste(drop_vars, collapse = ", "))
cat("\n\nDimensionen vorher: ", paste(dim(daten), collapse = " x "))
cat("\nDimensionen nachher: ", paste(dim(daten_clean), collapse = " x "))

readr::write_csv(daten_clean, here::here("data", "processed", "surf_clean.csv"))

```


# Insights: SURF Convenience Survey

